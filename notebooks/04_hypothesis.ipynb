{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_hypothesis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3MwCVkMA4h_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Key concepts\n",
        "1. Hypothesis testing\n",
        "2. Polls and sampling\n",
        "3. Margin of error\n",
        "4. T-tests and T-statistics\n",
        "5. Election simulation"
      ]
    },
    {
      "metadata": {
        "id": "B53QPJNJ4h_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.stats\n",
        "\n",
        "def coin_flip(p=0.5):\n",
        "    val = random.random()\n",
        "    if val < p:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def coin_flips(n=10, p=0.5):\n",
        "    rand = numpy.random.rand(n)\n",
        "    return rand[(rand < p)].size / n\n",
        "\n",
        "def random_avg(n=10):\n",
        "    res = 0\n",
        "    for i in range(n):\n",
        "        res += 10 * random.random()\n",
        "    return res / n\n",
        "\n",
        "def simulate(f, runs=10000):\n",
        "    return pd.DataFrame({'Val': [f() for i in range(runs)]})\n",
        "\n",
        "def poll_distribution(n, p):\n",
        "    res = 0\n",
        "    for i in range(10000):\n",
        "        res += coin_flips(n, p)\n",
        "    return res / 10000\n",
        "\n",
        "def histogram(df, bins=10):\n",
        "    if isinstance(df, pd.Series):\n",
        "        df = pd.DataFrame({df.name: df})\n",
        "    counts = df.assign(Count=1)\n",
        "    col_name = df.columns[0]\n",
        "    counts = counts.groupby(col_name).count()\n",
        "    df.plot.hist(bins=bins, xlim=(0, 1))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KR9RMod4h_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This could fail, that's ok.\n",
        "from ipywidgets import interact"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHToLRZg4h_g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hypothesis Testing 👩‍🔬\n",
        "\n",
        "To convert data into information, we use the scientific method. \n",
        "1. We have a **theory**\n",
        "2. We propose a **hypothesis** that should be true if our theory is true\n",
        "3. We think of data as an **experiment** to test our hypothesis\n",
        "\n",
        "Most hypotheses are negatives or null hypotheses, and we try to use the data to reject the null hypothesis.\n",
        "\n",
        "- Data does *not* follow a particular distribution\n",
        "- Two variables are *not* independent of each other\n",
        "\n",
        "We can never categorically disprove a null hypothesis. We can only say it is highly unlikely."
      ]
    },
    {
      "metadata": {
        "id": "BU3PSU1X4h_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the following exercise, we will test whether a sequence of coin flips comes from a biased coin by showing that it is highly unlikely to come from a fair coin.\n",
        "\n",
        "Let's say I rolled 55% heads out of 100 flips. How likely is that scenario with a normal coin?\n",
        "What if I rolled 55% heads out of 1000 flips.\n",
        "\n",
        "We can test that by running many simulations of a normal coin. We count the simulations that yielded at least 55% heads."
      ]
    },
    {
      "metadata": {
        "id": "_MArQg-c4h_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_estimate_out_of_bounds(num_samples, data_val, true_p=0.5, num_tests=10000):\n",
        "    success = 0\n",
        "    for i in range(num_tests):\n",
        "        sample = coin_flips(num_samples, true_p)\n",
        "        if data_val >= true_p:\n",
        "            # If this simultion yields at least as many heads as our data, \n",
        "            # then this distribution could have produced this data\n",
        "            if sample >= data_val:\n",
        "                success += 1\n",
        "        elif data_val <= true_p:\n",
        "            if sample <= data_val:\n",
        "                success += 1\n",
        "    return success / num_tests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQqx57em4h_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_estimate_out_of_bounds(10, 0.55)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjQChlZS4h_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TRY THIS\n",
        "Write a function to repeatedly flip a biased coin. \n",
        "How many attempts do you need before you can say that the chance of those flips being fair is less then 1%"
      ]
    },
    {
      "metadata": {
        "id": "3J4qLf4c4h_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# return the number of coin flips you need to make before it becomes highly unlikely (< 1%)\n",
        "# that those coin flips came from an unbiased coin.\n",
        "# NOTE: Do the test every 100 coin flips, because testing in this way is expensive.\n",
        "def detect_bias(bias=0.55):\n",
        "    num_heads = 0\n",
        "    num_flips = 0\n",
        "    while True:\n",
        "        # flip the biased coin\n",
        "        num_heads += ...\n",
        "        num_flips += 1\n",
        "        if num_flips % 100 == 0:\n",
        "            likelihood = test_estimate_out_of_bounds(..., ...)\n",
        "            if likelihood < 0.01:\n",
        "                return num_flips"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDCUsZKB4h_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detect_bias(0.55)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8LDYCCEh4h_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detect_bias(0.53)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nP1L1XjK4h_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detect_bias(0.51)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8k3_yRB14h_x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What happens is that the more coin flips you do, the tighter the range of possible probabilities \n",
        "that could have generated those flips. \n",
        "Also, the closer two distributions are, the more samples you need to prove the hypothesis that they are different\n"
      ]
    },
    {
      "metadata": {
        "id": "HY4Sh_ci4h_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@interact\n",
        "def h(flips=(50, 10000), bias=(0.0, 1.0)):\n",
        "    histogram(simulate(lambda: coin_flips(flips, bias)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kEbLfXq74h_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "histogram(simulate(lambda: coin_flips(1000, 0.5)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GL2ZtfCI4h_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "histogram(simulate(lambda: coin_flips(10000, 0.5)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "101OWy0H4h_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "histogram(simulate(lambda: coin_flips(100, 0.55)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yFOphHU84h_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "histogram(simulate(lambda: coin_flips(1000, 0.55)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqPCUvpX4h_9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "histogram(simulate(lambda: coin_flips(10000, 0.55)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1su1_m-5m7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "73321cfa-755d-4df7-8ccf-a2d22ea7c18d"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://<user>:<password>@github.com/haroldfox/ts-stuy-2019"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ts-stuy-2019'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 144 (delta 44), reused 58 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (144/144), 12.24 MiB | 5.57 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yeJRji114h_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "polls = pd.read_csv('ts-stuy-2019/datasets/presidential_polls.csv')\n",
        "polls = polls[pd.notnull(polls['samplesize'])]\n",
        "polls['samplesize'] = polls['samplesize'].astype(np.int64)\n",
        "electoral_college = pd.read_csv('ts-stuy-2019/datasets/electoral-college-votes.csv', names=['state', 'ElectoralVotes'])\n",
        "polls['Total'] = polls['rawpoll_clinton'] + polls['rawpoll_trump']\n",
        "polls['AdjTotal'] = polls['adjpoll_clinton'] + polls['adjpoll_trump']\n",
        "polls['Clinton'] = polls['rawpoll_clinton'] / polls['Total']\n",
        "polls['AdjClinton'] = polls['adjpoll_clinton'] / polls['AdjTotal']\n",
        "polls['AdjTrump'] = polls['adjpoll_trump'] / polls['AdjTotal']\n",
        "polls['Trump'] = polls['rawpoll_trump'] / polls['Total']\n",
        "polls = polls[(~polls['state'].str.contains('CD'))]\n",
        "polls = polls[['pollster', 'grade', 'state', 'Clinton', 'Trump', 'AdjClinton', 'AdjTrump', 'samplesize']]\n",
        "state_polls = polls[polls['state'] != 'U.S.'].groupby('state', as_index=False).first()\n",
        "state_polls = pd.merge(state_polls, electoral_college, on='state')\n",
        "national_polls = polls[polls['state'] == 'U.S.'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42zt9tVo4iAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A poll is like taking a sample of data from the true distribution. We imagine every American votes randomly accordingly to some true probability, `true_p`. A poll asks a small number of those Americans what their vote will be, and we use that sample to estimate `true_p`."
      ]
    },
    {
      "metadata": {
        "id": "Xxv-NajW4iAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "79976220-2a77-4548-e12e-7c75e46781c5"
      },
      "cell_type": "code",
      "source": [
        "national_polls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pollster</th>\n",
              "      <th>grade</th>\n",
              "      <th>state</th>\n",
              "      <th>Clinton</th>\n",
              "      <th>Trump</th>\n",
              "      <th>AdjClinton</th>\n",
              "      <th>AdjTrump</th>\n",
              "      <th>samplesize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Google Consumer Surveys</td>\n",
              "      <td>B</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>0.518004</td>\n",
              "      <td>0.481996</td>\n",
              "      <td>0.510636</td>\n",
              "      <td>0.489364</td>\n",
              "      <td>24316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABC News/Washington Post</td>\n",
              "      <td>A+</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>0.494505</td>\n",
              "      <td>0.505495</td>\n",
              "      <td>0.491859</td>\n",
              "      <td>0.508141</td>\n",
              "      <td>1128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pew Research Center</td>\n",
              "      <td>B+</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>0.534884</td>\n",
              "      <td>0.465116</td>\n",
              "      <td>0.517813</td>\n",
              "      <td>0.482187</td>\n",
              "      <td>2120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fox News/Anderson Robbins Research/Shaw &amp; Comp...</td>\n",
              "      <td>A</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.513715</td>\n",
              "      <td>0.486285</td>\n",
              "      <td>1221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>IBD/TIPP</td>\n",
              "      <td>A-</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>0.505096</td>\n",
              "      <td>0.494904</td>\n",
              "      <td>0.514804</td>\n",
              "      <td>0.485196</td>\n",
              "      <td>1018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            pollster grade state   Clinton  \\\n",
              "0                            Google Consumer Surveys     B  U.S.  0.518004   \n",
              "1                           ABC News/Washington Post    A+  U.S.  0.494505   \n",
              "4                                Pew Research Center    B+  U.S.  0.534884   \n",
              "5  Fox News/Anderson Robbins Research/Shaw & Comp...     A  U.S.  0.517647   \n",
              "6                                           IBD/TIPP    A-  U.S.  0.505096   \n",
              "\n",
              "      Trump  AdjClinton  AdjTrump  samplesize  \n",
              "0  0.481996    0.510636  0.489364       24316  \n",
              "1  0.505495    0.491859  0.508141        1128  \n",
              "4  0.465116    0.517813  0.482187        2120  \n",
              "5  0.482353    0.513715  0.486285        1221  \n",
              "6  0.494904    0.514804  0.485196        1018  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "YugJy9SU4iAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "state_polls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lm0Df4RI4iAI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TRY This\n",
        "\n",
        "Take a look at the national polls. \n",
        "Now look up the official national vote counts for Clinton and Trump.\n",
        "How accurate were those polls given the true probability. Use AdjClinton as the poll value."
      ]
    },
    {
      "metadata": {
        "id": "zYJbp4c-4iAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# return the likelihood of a particular poll result given the true election result.\n",
        "def test_poll(sample_size, poll_value, true_result):\n",
        "    return test_estimate_out_of_bounds(..., ..., ...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No4YDWtB4iAK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Margin of error\n",
        "What's important about a poll is not just its percentage, but its margin of error: the range of true percentages that would be consistent with it. Precisely, it means that the true percentage is within the poll's value with a high probability, generally 95%. "
      ]
    },
    {
      "metadata": {
        "id": "anCFhpBB4iAK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TRY This\n",
        "Look at the national polls.\n",
        "Given the true percentage, what range of true results would be consistent with that poll? \n",
        "Plug a range of different values into test_poll and choose the highest and lowest values which have likelihood > 5%\n",
        "\n",
        "Is the actual election result within the margin of error of the poll?"
      ]
    },
    {
      "metadata": {
        "id": "nfjbz9j64iAM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use test_poll above and try different values of the true_result parameter. \n",
        "# Start at the poll_value itself and increment it by 0.001 until the \n",
        "# likelihood that it is consistent with the true result is < 5%.\n",
        "# Return the difference between this largest, acceptable value and poll_value.\n",
        "def margin_of_error(sample_size, poll_value):\n",
        "    diff = 0\n",
        "    while True:\n",
        "        likelihood = test_estimate_out_of_bounds(..., ..., ...)\n",
        "        if likelihood < 0.05:\n",
        "          return diff * 2\n",
        "        diff += 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUgcCbA44iAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## T-stats and t-tests\n",
        "We don't have to use simulations to test whether our data matches some hypothetical normal distribution\n",
        "\n",
        "Instead, we can compute something called a t-statistic. The t-statistic itself follows a distribution, the t-distribution. When the computed t-statistic is an outlier value, then we can confidently reject our null hypothesis. Achieving that particular t-statistic by chance was too unlikely."
      ]
    },
    {
      "metadata": {
        "id": "juVVVS7R4iAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def t_stat(sample_size, poll_value, true_p):\n",
        "    sum_poll_values = poll_value * sample_size\n",
        "    s = sum_poll_values - (sum_poll_values * sum_poll_values) / sample_size\n",
        "    s = math.sqrt(s / (sample_size - 1))\n",
        "    return (poll_value - true_p) / (s / math.sqrt(sample_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heB6ZCam4iAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def t_test_poll(sample_size, poll_value, true_p):\n",
        "    t = t_stat(sample_size, poll_value, true_p)\n",
        "    likelihood = scipy.stats.t.sf(abs(t), sample_size - 1)\n",
        "    return likelihood"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O_xUgDt4iAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TRY This\n",
        "Calculate the margin of error again, this time using t_test_poll instead of test_poll"
      ]
    },
    {
      "metadata": {
        "id": "-bzz-Rkr4iAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def t_test_margin_of_error(sample_size, poll_value):\n",
        "    diff = 0\n",
        "    while True:\n",
        "        likelihood = t_test_poll(..., ..., ...)\n",
        "        if likelihood < 0.05:\n",
        "          return diff * 2\n",
        "        diff += 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsMYlkoR4iAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Election simulation 🗳️🇺🇸\n",
        "\n",
        "The USA uses the electoral college system, which is a lot more complex than a simple universal vote. Let's look at state polls to see what the electoral college estimates were. "
      ]
    },
    {
      "metadata": {
        "id": "_zXR6Ns94iAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# given a poll value and a sample size, we estimate the chance of Clinton winning as the \n",
        "# likelihood that the true probability for a state is at least 50%\n",
        "def chance_win(sample_size, poll_value):\n",
        "    t = t_stat(sample_size, poll_value, 0.5)\n",
        "    return scipy.stats.t.cdf(t, sample_size - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d23yH6kv4iAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "state_polls['WinProb'] = state_polls.apply(lambda row: chance_win(row['samplesize'], row['AdjClinton']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-uUOKJV4iAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# swing states\n",
        "state_polls[(state_polls['WinProb'] >= 0.01) & (state_polls['WinProb'] <= 0.99)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VAazxIR4iAe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "1. Run a simulation of 10000 elections. For each simulation, for each state, simulate whether\n",
        "Clinton wins the state according to the WinProb column. If Clinton gets over 270 electoral votes, she wins. How many simulated elections does Clinton win in this way?\n",
        "Does this seem accurate? Look at state_polls. What seems wrong?\n",
        "What happens if we increase our uncertainty about winning by lowering the effective sample size to 100?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZPYValqV4iAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Does this seem accurate? Look at state_polls. What seems wrong?"
      ]
    },
    {
      "metadata": {
        "id": "8gQXcFCB4iAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. What happens if we increase our uncertainty about winning by lowering the effective sample size to 100?\n",
        "\n",
        "3. Investigate the idea a systematic polling bias (Nate Silver has this idea in his predictions). We're not sure what the direction of the bias may be, but it affects every poll. Run a simulation of 10,000 elections as in exercise #1. Sample a poll-bias value from the normal distribution, then for each state, subtract this poll-bias from the poll value, calculate the new probability of winning, and simulate the state's outcome based on this probability. With the systematic polling bias term, now what is the probability of Clinton or Trump?"
      ]
    }
  ]
}