{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Started "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome\n",
    "\n",
    "Welcome to Jupyter, a notebook environment for python. We will use Jupyter notebooks throughout this course to explore, visualize, and analyze data. You can learn more about Jupyter here: http://jupyter.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required python libraries\n",
    "\n",
    "We begin by importing a few basic python libraries for data analysis and visualization. We will start with the following:\n",
    "\n",
    "- pandas: data analysis\n",
    "- numpy: numerical computing and linear algebra in python\n",
    "- datetime: date and time functionality\n",
    "- matplotlib: plotting and data visualization tools\n",
    "- seaborn: interface to matplotlib for easier (and prettier) plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # We give the libraries short names for easier referencing\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "# This allows us to display plots right within our Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set notebook display options\n",
    "\n",
    "Pandas is a python library for data analysis. We will begin by using it here to set display options so that we can see a larger number of rows and columns than the default. You can read more about setting options here: https://pandas.pydata.org/pandas-docs/stable/options.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- What is the default maximum number of columns displayed?\n",
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- What is the default maximum number of rows displayed?\n",
    "pd.options.display.max_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- We can change the default number of rows and columns\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Which other kinds of options are available?\n",
    "dir(pd.options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read documentation in your Jupyter notebook\n",
    "Jupyter conveniently allows us to read documentation on python functions and other objects within our notebook. This can be done by either preceding or following the name of the object with a '?' (question mark). We illustrate this here with the 'set_option' function provided by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- \n",
    "'''\n",
    "Getting Familiar with the ipython notebook environment\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "Session 1: Exploring Data in Python\n",
    "\n",
    "1.\tGetting Started\n",
    "    - working in jupyter\n",
    "    - display options\n",
    "    - importing libraries (and what these libraries contain)\n",
    "2.\tIntroduction to pandas\n",
    "    - python brief review (control structures, data structures, functions, lambda)\n",
    "    - pandas \n",
    "        - \n",
    "3.\tLoading and Summarizing Data\n",
    "4.\tVisualizing Data in pandas\n",
    "    - \n",
    "\n",
    "5.\tCleaning and Tidying Data\n",
    "\n",
    "Session 2: Visualizing and Simulating Data\n",
    "\n",
    "1.\tBrief Recap of Last Session\n",
    "    - What did we learn last time?\n",
    "    - Review \n",
    "2.\tData Visualization\n",
    "- \n",
    "3.\tHandling Missing Data\n",
    "4.\tRandom Numbers and Sampling\n",
    "5.\tSimulation for Data Analysis\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all this information and more, see https://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we'll be making extensive use of a Python library called Pandas. You may be familiar with native python data structures like lists and dictionaries. Pandas offers two data structures called DataFrames and Series which have a lot of built-in functionality that makes analyzing data easy.   \n",
    "\n",
    "Let's start off by introducing the Series. Series objects are similar in flavor to dictionaries. They have an 'index' that you can think of as the key of a dictionary, which maps to values. In fact, you can create a Series from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_dict = {i:2*i for i in range(10)} # This is called 'list comprehension'! \n",
    "sers = pd.Series(underlying_dict)\n",
    "sers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access entries by .loc:\n",
    "sers.loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index need not be an integer. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_dict = {'a':0, 'b':1, 'c':2}\n",
    "pd.Series(underlying_dict).loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also make a Series from a list if you use Pandas' \n",
    "# default integer index:\n",
    "pd.Series([2*i for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of a DataFrame as a 2D array or matrix. Like a Series, a DataFrame has an index, but DataFrames also have different columns. We can build up a DataFrame as a dictionary of multiple Series':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sers_one = pd.Series({'a':0,'b':1,'c':2})\n",
    "sers_two = pd.Series({'a':3,'b':4,'c':5})\n",
    "my_first_df = pd.DataFrame({'sers_one':sers_one, 'sers_two':sers_two})\n",
    "my_first_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a column this way:\n",
    "my_first_df['sers_one']\n",
    "\n",
    "# Access a row this way:\n",
    "my_first_df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build up a DataFrame much faster than that. For instance, \n",
    "# check the output of the following: np.random.normal(size=(10,3))\n",
    "# It returns a 2D array of normal random variables. \n",
    "\n",
    "my_second_df = pd.DataFrame(\n",
    "    np.random.normal(size=(10,3)),columns = ['a','b','c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a function that takes in rows of a DataFrame and spits out a number. We may want to apply this function to each row of our DataFrame and store the results in a new Series. Below, let's make up a simple function, and use a for-loop to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return 2.*row['a']-row['b']*(row['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apply_f_to_rows = {}\n",
    "for i,row in my_second_df.iterrows():\n",
    "    apply_f_to_rows[i] = f(row)\n",
    "apply_f_to_rows = pd.Series(apply_f_to_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can accomplish the above with a single line of code using df.apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we set axis = 1 to specify that we want the function to be applied to each row.\n",
    "# If you come up with a function that can take columns, you should set axis = 0\n",
    "apply_f_to_rows_faster = my_second_df.apply(f,axis = 1)\n",
    "\n",
    "# Test that the two results are the same!\n",
    "# Hint: remember that to test if two values are the same we use ==\n",
    "# Try np.all([True,True,False]) for a counter example:\n",
    "np.all(apply_f_to_rows_faster == apply_f_to_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TRY THIS!**\n",
    "\n",
    "Make up a function that takes in columns of a DataFrame and try modifying the argument 'axis' in df.apply to see the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter DataFrames as well if we are only interested in data that matches a certain condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_df[my_second_df['a']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this work? Look at the return values of #my_second_df['a']>0. It returns a Series of booleans with the same index as my_second_df. We can use more complicated filtering as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_df['a']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complicated filtering:\n",
    "my_second_df[(my_second_df['a']>0) & (my_second_df['b']<0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas lets us easily apply functions to entire data sets as well. For instance, if we want to sum up the columns, find the standard deviation of each column, or the mean of the column, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the following operations returns a Series.\n",
    "# Try passing in the 'axis' argument to each operation, \n",
    "# and set it to 0 or 1 to compare the results:\n",
    "my_second_df.sum()\n",
    "my_second_df.std()\n",
    "my_second_df.mean()\n",
    "my_second_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate some cool features of dataframes, let's make up a dataset. The columns can be genre, total revenue (in $M), and number of viewers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = np.random.choice(['scary', 'funny', 'action packed'], 20)\n",
    "revenue = 100.*np.random.normal(size = 20)**2\n",
    "viewers = np.random.randint(100, size = 20)\n",
    "fake_movies = pd.DataFrame(\n",
    "    {'genres':genres, 'revenue': revenue, 'viewers': viewers})\n",
    "fake_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try grouping by genre:\n",
    "grouped = fake_movies.groupby(genres)\n",
    "grouped.get_group('funny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we'll want to apply a function to the DataFrames that result from a groupby. For instance if we want to group 'fake_movies' by genre, and then find the average revenue and average number of viewers for each genre, we can accomplish this in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_movies.groupby(genres).apply(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about how to create DataFrames, and how to group them and apply functions to them. One common problem you'll run in to is combining DataFrames. If you are given two data sets that share a common feature (such as a column of times), you may want to put the two data sets together into a single DataFrame.\n",
    "\n",
    "Here, we'll explore how to 'merge' two DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, let's create a column of times for our two datasets,\n",
    "# we'll call them df_left and df_right.\n",
    "# To join, they don't have to have the same length:\n",
    "\n",
    "date0 = datetime.date(2015,1,1)\n",
    "times_left = [date0 + datetime.timedelta(i) for i in range(10)]\n",
    "times_right = [date0 + datetime.timedelta(i) for i in range(12)]\n",
    "\n",
    "df_left = pd.DataFrame(\n",
    "    np.random.normal(size=(10,2)), columns = ['a','b'])\n",
    "df_right = pd.DataFrame(\n",
    "    np.random.normal(size=(12,3)), columns = ['c','d','e'])\n",
    "\n",
    "# We can add new columns very easily:\n",
    "df_left['times'] = times_left\n",
    "df_right['times'] = times_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left.merge(df_right, how = 'inner', on = 'times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TRY THIS!**\n",
    "\n",
    "Try changing 'how' to 'outer' above to compare what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading and Summarizing Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Data can be loaded into a pandas data frame from a variety of file formats. In this session, we will load data on 5000 movies in The Movie Database (TMDB) from a csv file. To see the first few rows of a data frame, use df.head() as in the example below.\n",
    "\n",
    "This dataset is available online on Kaggle: https://www.kaggle.com/tmdb/tmdb-movie-metadata\n",
    "There are many other datasets available from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TRY THIS!**\n",
    "\n",
    "What happens if we change the argument to DataFrame.head() from 10 to a different number? What if we delete the argument entirely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/kaggle/tmdb_data.csv')\n",
    "data.head(10)  # Try changing the number of rows and removing the argument to check what pandas uses as the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.title_year.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('actor_2_name').count()['popularity'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the dimensions of a data frame using df.shape. For example, here we see that our movies data has 4803 rows and 26 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the names of columns in a data frame using df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When in doubt about the correct way to call a function or use a python object, we can access documentation on it from \n",
    "right within the notebook by following its name with a '?' (question mark)\n",
    "The line below retrieves documentation on the 'read_csv' function that we used above to load data from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display summary and descriptive statistics\n",
    "We can summarize the contents of a data frame using the df.describe() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select rows and columns using .loc\n",
    "We can select rows and columns of a data frame using .loc, a versatile method that allows us to specify rows and columns either by label or by specifying a condition that needs to be true. Which of the movies in the dataset grossed over $1 billion?\n",
    "\n",
    "1. We use loc to select the original_title and gross amount columns for all movies that grossed over $1 billion (1e9).\n",
    "2. We sort the selected data by gross amount (descending) to rank the highest-grossing movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.gross>1e9,['original_title', 'gross']].sort_values('gross', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TRY THIS!**\n",
    "Ask some interesting questions about the movie data that can be answered by filtering and sorting or ranking the dataset. Then answer the questions using what you have learned about .loc and .sort_values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data\n",
    "How many movies from each year of release are in the dataset? We can find out easily by first grouping the data by genre and then counting the number of rows in each genre as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('title_year').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group on filtered data\n",
    "If we only want the movies per year for the past ten years (2007-2016) then we can first filter the data, then count the number of movies in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.title_year<2017)&(data.title_year>=2007), :].groupby('title_year')[['id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Data in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data from a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.title_year<2017)&(data.title_year>=2007), :].groupby('title_year')[['id']].count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.title_year<2017)&(data.title_year>=2007), :].groupby('title_year')[['id']].count().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a histogram to visualize the distribution of a variable. We can specify the number of bins in the histogram to change its level of granularity. What is the distribution of the duration of movies in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** TRY THIS! **\n",
    "Change the number of bins in the histogram below to smaller and larger values. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel density estimate (KDE) is a smoothed visualization of the distribution of a variable. Below is the KDE for movie duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- 'line' : line plot (default)\n",
    "    - 'bar' : vertical bar plot\n",
    "    - 'barh' : horizontal bar plot\n",
    "    - 'hist' : histogram\n",
    "    - 'box' : boxplot\n",
    "    - 'kde' : Kernel Density Estimation plot\n",
    "    - 'density' : same as 'kde'\n",
    "    - 'area' : area plot\n",
    "    - 'pie' : pie plot\n",
    "    - 'scatter' : scatter plot\n",
    "    - 'hexbin' : hexbin plot\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.title_year<2017)&(data.title_year>=2007), :].groupby('title_year')[['id']].count().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleaning and Tidying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
